{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d186179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность AdaBoost: 0.8100\n",
      "Количество классификаторов: 100\n",
      "Веса классификаторов: [np.float64(0.4118000344786902), np.float64(0.21801223556400137), np.float64(0.2582862763391271), np.float64(0.23846063311561497), np.float64(0.21380702536287824)]...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "\n",
    "class AdaBoostClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Реализация алгоритма AdaBoost для бинарной и мультиклассовой классификации\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=50, max_depth=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.classifier_weights = []\n",
    "        self.classifiers = []\n",
    "        self.weights_history = []\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение AdaBoost модели с обработкой различных типов меток\n",
    "        \"\"\"\n",
    "        # Проверка и преобразование меток\n",
    "        check_classification_targets(y)\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        # Преобразуем метки к формату {-1, 1} для бинарной классификации\n",
    "        if len(self.label_encoder.classes_) == 2:\n",
    "            y_transformed = np.where(y_encoded == 0, -1, 1)\n",
    "        else:\n",
    "            # Для мультиклассовой используем оригинальные метки\n",
    "            y_transformed = y_encoded\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # 1. ИНИЦИАЛИЗАЦИЯ ВЕСОВ ОБЪЕКТОВ\n",
    "        weights = np.ones(n_samples) / n_samples\n",
    "        self.weights_history.append(weights.copy())\n",
    "        \n",
    "        for t in range(self.n_estimators):\n",
    "            # 2. ОБУЧЕНИЕ БАЗОВОГО КЛАССИФИКАТОРА\n",
    "            classifier = self._train_base_classifier(X, y_transformed, weights)\n",
    "            \n",
    "            # 3. ВЫЧИСЛЕНИЕ ОШИБКИ КЛАССИФИКАТОРА\n",
    "            error = self._calculate_classifier_error(X, y_transformed, weights, classifier)\n",
    "            \n",
    "            # 4. ВЫЧИСЛЕНИЕ ВЕСА КЛАССИФИКАТОРА\n",
    "            alpha = self._calculate_alpha(error)\n",
    "            self.classifier_weights.append(alpha)\n",
    "            self.classifiers.append(classifier)\n",
    "            \n",
    "            # 5. ОБНОВЛЕНИЕ ВЕСОВ ОБЪЕКТОВ\n",
    "            weights = self._update_sample_weights(X, y_transformed, weights, classifier, alpha)\n",
    "            self.weights_history.append(weights.copy())\n",
    "            \n",
    "            # Ранняя остановка если ошибка равна 0 или слишком мала\n",
    "            if error < 1e-10:\n",
    "                break\n",
    "    \n",
    "    def _train_base_classifier(self, X, y, weights):\n",
    "        \"\"\"Обучение слабого классификатора\"\"\"\n",
    "        classifier = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "        classifier.fit(X, y, sample_weight=weights)\n",
    "        return classifier\n",
    "    \n",
    "    def _calculate_classifier_error(self, X, y, weights, classifier):\n",
    "        \"\"\"Вычисление взвешенной ошибки\"\"\"\n",
    "        predictions = classifier.predict(X)\n",
    "        \n",
    "        # Убеждаемся, что типы данных совместимы\n",
    "        predictions = predictions.astype(y.dtype)\n",
    "        incorrect = (predictions != y)\n",
    "        \n",
    "        error = np.sum(weights[incorrect]) / np.sum(weights)\n",
    "        return error\n",
    "    \n",
    "    def _calculate_alpha(self, error):\n",
    "        \"\"\"Вычисление веса классификатора\"\"\"\n",
    "        epsilon = 1e-10\n",
    "        error = np.clip(error, epsilon, 1 - epsilon)\n",
    "        return 0.5 * np.log((1 - error) / error)\n",
    "    \n",
    "    def _update_sample_weights(self, X, y, weights, classifier, alpha):\n",
    "        \"\"\"Обновление весов объектов\"\"\"\n",
    "        predictions = classifier.predict(X)\n",
    "        \n",
    "        # Убеждаемся, что типы данных совместимы\n",
    "        predictions = predictions.astype(y.dtype)\n",
    "        \n",
    "        # Правильно вычисляем множители\n",
    "        incorrect_mask = (predictions != y)\n",
    "        multipliers = np.exp(alpha * incorrect_mask.astype(float))\n",
    "        \n",
    "        # Обновляем веса\n",
    "        new_weights = weights * multipliers\n",
    "        new_weights /= np.sum(new_weights)  # Нормализация\n",
    "        \n",
    "        return new_weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание меток для новых данных\"\"\"\n",
    "        # Взвешенное голосование ансамбля\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        \n",
    "        for alpha, classifier in zip(self.classifier_weights, self.classifiers):\n",
    "            pred = classifier.predict(X)\n",
    "            predictions += alpha * pred\n",
    "        \n",
    "        # Для бинарной классификации возвращаем к оригинальным меткам\n",
    "        if len(self.label_encoder.classes_) == 2:\n",
    "            final_predictions = np.where(predictions >= 0, \n",
    "                                       self.label_encoder.classes_[1], \n",
    "                                       self.label_encoder.classes_[0])\n",
    "        else:\n",
    "            # Для мультиклассовой - используем знак или округление\n",
    "            final_predictions = self.label_encoder.inverse_transform(\n",
    "                np.round(predictions).astype(int)\n",
    "            )\n",
    "        \n",
    "        return final_predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Предсказание вероятностей классов\"\"\"\n",
    "        score = np.zeros(X.shape[0])\n",
    "        \n",
    "        for alpha, classifier in zip(self.classifier_weights, self.classifiers):\n",
    "            pred = classifier.predict(X)\n",
    "            score += alpha * pred\n",
    "        \n",
    "        # Преобразуем score в вероятности\n",
    "        if len(self.label_encoder.classes_) == 2:\n",
    "            probabilities = 1 / (1 + np.exp(-2 * score))\n",
    "            return np.column_stack([1 - probabilities, probabilities])\n",
    "        else:\n",
    "            # Для мультиклассовой используем softmax\n",
    "            from scipy.special import softmax\n",
    "            return softmax(score.reshape(-1, 1), axis=1)\n",
    "\n",
    "# ДЕМОНСТРАЦИЯ С ПРАВИЛЬНОЙ ОБРАБОТКОЙ ДАННЫХ\n",
    "def demonstrate_adaboost_fixed():\n",
    "    \"\"\"Демонстрация работы AdaBoost с правильной обработкой данных\"\"\"\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    # Генерация синтетических данных\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, \n",
    "                              n_informative=15, n_redundant=5,\n",
    "                              random_state=42)\n",
    "    \n",
    "    # Разделение на train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Создание и обучение AdaBoost\n",
    "    adaboost = AdaBoostClassifier(n_estimators=100, max_depth=1)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказание и оценка качества\n",
    "    y_pred = adaboost.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Точность AdaBoost: {accuracy:.4f}\")\n",
    "    print(f\"Количество классификаторов: {len(adaboost.classifiers)}\")\n",
    "    print(f\"Веса классификаторов: {adaboost.classifier_weights[:5]}...\")\n",
    "\n",
    "# Запуск демонстрации\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_adaboost_fixed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
